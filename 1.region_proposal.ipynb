{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np           \n",
    "import xml.etree.ElementTree as Et\n",
    "from PIL import Image as im\n",
    "import math \n",
    "from sklearn.linear_model import Ridge\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import datasets,transforms,models\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as im\n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# obj_class =[]\n",
    "# for e,i in enumerate(os.listdir( annot_path)):\n",
    "#     xml =  open(os.path.join(annot_path, i), \"r\")\n",
    "#     tree = Et.parse(xml)\n",
    "#     root = tree.getroot()\n",
    "#     objects = root.findall(\"object\")\n",
    "#     obj_class = obj_class + [_object.find('name').text for _object in objects ]\n",
    "#     obj_class = list(set(obj_class))\n",
    "#     if len(obj_class) == 20:\n",
    "#         break\n",
    "\n",
    "\n",
    "obj_class = ['person', \n",
    "           'bird', \n",
    "           'cat', \n",
    "           'cow', \n",
    "           'dog',    # 5\n",
    "           'horse', \n",
    "           'sheep', \n",
    "           'aeroplane', \n",
    "           'bicycle', \n",
    "           'boat',   # 10\n",
    "           'bus', \n",
    "           'car', \n",
    "           'motorbike', \n",
    "           'train', \n",
    "           'bottle', \n",
    "           'chair',  # 16\n",
    "           'diningtable', \n",
    "           'pottedplant', \n",
    "           'sofa', \n",
    "           'tvmonitor'\n",
    "           ]\n",
    "\n",
    "obj_class = ['background'] + obj_class\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data set: 5011\n"
     ]
    }
   ],
   "source": [
    "li=os.listdir('VOC2007_train_val/JPEGImages')\n",
    "print('total data set:',len(li))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VOC dataset을 selective search한 결과를 폴더에 저장하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: 0\n",
      "Success: 100\n",
      "Success: 200\n",
      "Success: 300\n",
      "Success: 400\n",
      "Success: 500\n",
      "Success: 600\n",
      "Success: 700\n",
      "Success: 800\n",
      "Success: 900\n",
      "Success: 1000\n",
      "Success: 1100\n",
      "Success: 1200\n",
      "Success: 1300\n",
      "Success: 1400\n",
      "Success: 1500\n",
      "Success: 1600\n",
      "Success: 1700\n",
      "Success: 1800\n",
      "Success: 1900\n",
      "Success: 2000\n",
      "Success: 2100\n",
      "Success: 2200\n",
      "Success: 2300\n",
      "Success: 2400\n",
      "Success: 2500\n",
      "Success: 2600\n",
      "Success: 2700\n",
      "Success: 2800\n",
      "Success: 2900\n",
      "Success: 3000\n",
      "Success: 3100\n",
      "Success: 3200\n",
      "Success: 3300\n",
      "Success: 3400\n",
      "Success: 3500\n",
      "Success: 3600\n",
      "Success: 3700\n",
      "Success: 3800\n",
      "Success: 3900\n",
      "Success: 4000\n",
      "Success: 4100\n",
      "Success: 4200\n",
      "Success: 4300\n",
      "Success: 4400\n",
      "Success: 4500\n",
      "Success: 4600\n",
      "Success: 4700\n",
      "Success: 4800\n",
      "Success: 4900\n",
      "Success: 5000\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "annot_path='VOC2007_train_val/Annotations'      # annotaion data가 있는 경로\n",
    "img_path='VOC2007_train_val/JPEGImages'      # 이미지 데이터가 있는 경로\n",
    "count=0\n",
    "count_back=0\n",
    "\n",
    "for e,i in enumerate(os.listdir(annot_path)):   # annotatoin 파일을 읽어서 정보를 저장 파일 하나에 여러개의 물체의 정보가 있을수 있음\n",
    "    filename = i.split(\".\")[0]\n",
    "    img_file = i.split(\".\")[0]+\".jpg\"\n",
    "    if e%100 == 0:\n",
    "        print('Success:', e)\n",
    "    image = cv2.imread(os.path.join(img_path,img_file))\n",
    "    xml =  open(os.path.join(annot_path, i), \"r\")\n",
    "    tree = Et.parse(xml)\n",
    "    root = tree.getroot()\n",
    "    objects = root.findall(\"object\")\n",
    "    imout = image.copy()\n",
    "    \n",
    "    \n",
    "    bb_values=[]\n",
    "    for _object in objects:               # ground truth 정보 저장\n",
    "        bndbox = _object.find('bndbox')   # object -> bndbox 객체 반환\n",
    "        obj_name = _object.find('name').text   \n",
    "        xmin = int(bndbox.find('xmin').text)\n",
    "        xmax = int(bndbox.find('xmax').text)\n",
    "        ymin = int(bndbox.find('ymin').text)\n",
    "        ymax = int(bndbox.find('ymax').text)\n",
    "        bb_values.append({\"name\": obj_name,\"xmin\":xmin,\"xmax\":xmax,\"ymin\":ymin,\"ymax\":ymax})\n",
    "        \n",
    "\n",
    "\n",
    "    ss.setBaseImage(image)                    # 위 annotation파일과 대응되는 image파일 한장에서 \n",
    "    ss.switchToSelectiveSearchFast()          # selective search 알고리즘으로 객체가 있을법한 영역 검출\n",
    "    ssresults = ss.process()                  # e번쨰 이미지에서 (266(selective search로 찾은 박스),4)\n",
    "    imout = image.copy()\n",
    " \n",
    "\n",
    "    \n",
    "\n",
    "    for e1,result in enumerate(ssresults):\n",
    "        if e1 < 2000:\n",
    "            for gtval in bb_values:\n",
    "                label=obj_class.index(gtval['name'])# 0~20, 0 -> background\n",
    "                \n",
    "                x,y,w,h = result\n",
    "                iou = get_iou(gtval,{\"xmin\":x,\"xmax\":x+w,\"ymin\":y,\"ymax\":y+h})   # ground truth에 존재하는 객체의 박스와 selective search 로 찾은 박스의 IOU를 계산\n",
    "                \n",
    "                path='data/'+str(label)\n",
    "                if os.path.exists(path)==False:\n",
    "                    os.makedirs(path)\n",
    "\n",
    "                if iou > 0.50:\n",
    "                    timage = imout[y:y+h,x:x+w]\n",
    "                    resized = cv2.resize(timage, (224,224), interpolation = cv2.INTER_AREA)  # 선택된 영역 resize\n",
    "                    cv2.imwrite('data/{}/{}.jpg'.format(label,count),resized)\n",
    "                else:\n",
    "                    if count_back>100000:\n",
    "                        continue\n",
    "                    else:\n",
    "                        timage = imout[y:y+h,x:x+w]\n",
    "                        resized = cv2.resize(timage, (224,224), interpolation = cv2.INTER_AREA)\n",
    "                        cv2.imwrite('data/0/{}.jpg'.format(count_back),resized)\n",
    "                        count_back+=1\n",
    "                count+=1\n",
    "       \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "joowan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b94245a966602fa1d3337cb3b1178b7109c129cd4eabde98685205c86aedb4a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
